"""LLM patch generation agent.

Given an `AgentOpportunity` and the repo directory, asks the LLM to produce
search/replace edits rather than a raw unified diff.  The LLM only needs to
quote the exact text it wants to change and provide the replacement — no line
counting, no hunk headers.  The unified diff is then generated by Python's
`difflib.unified_diff`, which always produces a syntactically correct diff.

The agent includes a self-healing fallback: if the search block is not found
(or is ambiguous), the error is appended to the approach and the LLM is
called again to fix its edit.
"""

import difflib
import json
import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional

from runner.agent.types import AgentOpportunity, AgentPatch
from runner.llm.prompts.patch_prompts import patch_generation_prompt
from runner.llm.prompts.system_prompts import build_system_prompt
from runner.llm.provider import LLMProvider, LLMProviderError
from runner.llm.types import LLMConfig, LLMMessage, ThinkingTrace
from runner.patchgen.constraints import enforce_constraints
from runner.patchgen.types import ConstraintViolation, PatchResult

logger = logging.getLogger(__name__)

# Max characters of file content to send in a single patch generation call (20KB)
MAX_FILE_CHARS = 20_000


def _patchgen_config(config: LLMConfig) -> LLMConfig:
    """Return a config tuned for patch generation.

    Uses a 4000-token thinking budget for Anthropic (down from 8000) and
    keeps reasoning_effort=high for OpenAI reasoning models.
    """
    from dataclasses import replace
    return replace(config, thinking_budget_tokens=4000)

# Maximum self-correction attempts when a constraint is violated
MAX_SELF_CORRECTION_ATTEMPTS = 1


PATCHGEN_FAILURE_STAGE_LLM_CALL = "llm_call"
PATCHGEN_FAILURE_STAGE_JSON_PARSE = "json_parse"
PATCHGEN_FAILURE_STAGE_NULL_DIFF = "null_diff"
PATCHGEN_FAILURE_STAGE_SEARCH_NOT_FOUND = "search_not_found"
PATCHGEN_FAILURE_STAGE_CONSTRAINT = "constraint"
PATCHGEN_FAILURE_STAGE_FILE_MISSING = "file_missing"
PATCHGEN_FAILURE_STAGE_FILE_READ = "file_read"
PATCHGEN_FAILURE_STAGE_UNKNOWN = "unknown"


@dataclass
class PatchGenTryRecord:
    attempt_number: int
    success: bool
    failure_stage: Optional[str] = None
    failure_reason: Optional[str] = None
    patch: Optional[AgentPatch] = None
    patch_trace: Optional[ThinkingTrace] = None


@dataclass
class PatchGenerationOutcome:
    success: bool
    patch: Optional[AgentPatch]
    failure_stage: Optional[str] = None
    failure_reason: Optional[str] = None
    tries: list[PatchGenTryRecord] = field(default_factory=list)


async def generate_agent_patch(
    opportunity: AgentOpportunity,
    repo_dir: Path,
    provider: LLMProvider,
    config: LLMConfig,
    approach_override: Optional[str] = None,
) -> Optional[AgentPatch]:
    """Generate a patch for an `AgentOpportunity` using the LLM.

    Args:
        opportunity: The opportunity to fix.
        repo_dir: Absolute path to the checked-out repository.
        provider: Instantiated LLM provider.
        config: LLM configuration.
        approach_override: When set, replaces `opportunity.approach` in the
            patch prompt. Used by the multi-approach loop to try different
            implementation strategies for the same opportunity.

    Returns:
        An `AgentPatch` if the LLM produced a valid, constraint-compliant
        diff, or None if no valid patch could be generated.
    """
    outcome = await generate_agent_patch_with_diagnostics(
        opportunity=opportunity,
        repo_dir=repo_dir,
        provider=provider,
        config=config,
        approach_override=approach_override,
    )
    return outcome.patch


async def generate_agent_patch_with_diagnostics(
    opportunity: AgentOpportunity,
    repo_dir: Path,
    provider: LLMProvider,
    config: LLMConfig,
    approach_override: Optional[str] = None,
) -> PatchGenerationOutcome:
    """Generate a patch and return detailed diagnostics for live event streaming."""
    repo_dir = Path(repo_dir)

    file_rel_path = _parse_file_from_location(opportunity.location)
    if not file_rel_path:
        logger.warning("Cannot parse file from opportunity location: %s", opportunity.location)
        return PatchGenerationOutcome(
            success=False,
            patch=None,
            failure_stage=PATCHGEN_FAILURE_STAGE_UNKNOWN,
            failure_reason=f"Cannot parse file from opportunity location: {opportunity.location}",
            tries=[],
        )

    file_path = repo_dir / file_rel_path
    if not file_path.is_file():
        logger.warning("Opportunity file not found: %s", file_path)
        return PatchGenerationOutcome(
            success=False,
            patch=None,
            failure_stage=PATCHGEN_FAILURE_STAGE_FILE_MISSING,
            failure_reason=f"Opportunity file not found: {file_path}",
            tries=[],
        )

    try:
        content = file_path.read_text(encoding="utf-8", errors="replace")
    except OSError as exc:
        logger.error("Cannot read %s: %s", file_path, exc)
        return PatchGenerationOutcome(
            success=False,
            patch=None,
            failure_stage=PATCHGEN_FAILURE_STAGE_FILE_READ,
            failure_reason=str(exc),
            tries=[],
        )

    if len(content) > MAX_FILE_CHARS:
        content = content[:MAX_FILE_CHARS] + "\n\n... [file truncated at 20KB] ..."

    effective_approach = approach_override if approach_override is not None else opportunity.approach
    tries: list[PatchGenTryRecord] = []

    for attempt in range(1 + MAX_SELF_CORRECTION_ATTEMPTS):
        try_record = await _call_patch_agent_with_diagnostics(
            attempt_number=attempt + 1,
            file_rel_path=file_rel_path,
            content=content,
            opportunity=opportunity,
            approach=effective_approach,
            provider=provider,
            config=config,
        )
        tries.append(try_record)

        if not try_record.success or try_record.patch is None:
            stage = try_record.failure_stage
            # search_not_found and json_parse are recoverable: the LLM made a
            # transcription error that corrective feedback can fix.  Retry once
            # with an explicit description of what went wrong.
            if attempt < MAX_SELF_CORRECTION_ATTEMPTS and stage in (
                PATCHGEN_FAILURE_STAGE_SEARCH_NOT_FOUND,
                PATCHGEN_FAILURE_STAGE_JSON_PARSE,
            ):
                logger.info(
                    "Patch generation failed on attempt %d (%s); retrying with corrective feedback",
                    attempt + 1, stage,
                )
                effective_approach = _build_correction_feedback(
                    effective_approach, stage, try_record.failure_reason or "",
                )
                continue

            return PatchGenerationOutcome(
                success=False,
                patch=None,
                failure_stage=try_record.failure_stage,
                failure_reason=try_record.failure_reason,
                tries=tries,
            )

        patch = try_record.patch
        try:
            proxy_result = PatchResult(
                diff=patch.diff,
                explanation=patch.explanation,
                touched_files=patch.touched_files,
                template_name="llm_agent",
                lines_changed=patch.estimated_lines_changed,
            )
            enforce_constraints(proxy_result)
            return PatchGenerationOutcome(
                success=True,
                patch=patch,
                failure_stage=None,
                failure_reason=None,
                tries=tries,
            )
        except ConstraintViolation as exc:
            try_record.success = False
            try_record.failure_stage = PATCHGEN_FAILURE_STAGE_CONSTRAINT
            try_record.failure_reason = str(exc)
            if attempt < MAX_SELF_CORRECTION_ATTEMPTS:
                logger.info(
                    "Patch constraint violation on attempt %d, retrying: %s",
                    attempt + 1, exc,
                )
                effective_approach = (
                    f"{effective_approach}\n\n"
                    f"PREVIOUS ATTEMPT FAILED constraint check: {exc}. "
                    "Produce a smaller, more focused diff that stays within limits."
                )
                continue

            logger.warning("Patch rejected after %d attempts: %s", attempt + 1, exc)
            return PatchGenerationOutcome(
                success=False,
                patch=None,
                failure_stage=PATCHGEN_FAILURE_STAGE_CONSTRAINT,
                failure_reason=str(exc),
                tries=tries,
            )

    return PatchGenerationOutcome(
        success=False,
        patch=None,
        failure_stage=PATCHGEN_FAILURE_STAGE_UNKNOWN,
        failure_reason="Patch generation failed without a recorded outcome",
        tries=tries,
    )


async def _call_patch_agent(
    file_rel_path: str,
    content: str,
    opportunity: AgentOpportunity,
    approach: str,
    provider: LLMProvider,
    config: LLMConfig,
) -> Optional[AgentPatch]:
    """Make one patch generation LLM call and parse the result."""
    try_record = await _call_patch_agent_with_diagnostics(
        attempt_number=1,
        file_rel_path=file_rel_path,
        content=content,
        opportunity=opportunity,
        approach=approach,
        provider=provider,
        config=config,
    )
    return try_record.patch


async def _call_patch_agent_with_diagnostics(
    attempt_number: int,
    file_rel_path: str,
    content: str,
    opportunity: AgentOpportunity,
    approach: str,
    provider: LLMProvider,
    config: LLMConfig,
) -> PatchGenTryRecord:
    """Make one patch generation LLM call and capture parse diagnostics."""
    from runner.detector.types import DetectionResult
    system_prompt = build_system_prompt(DetectionResult())  # Generic for patch gen

    prompt = patch_generation_prompt(
        file_path=file_rel_path,
        content=content,
        opportunity_type=opportunity.type,
        rationale=opportunity.rationale,
        approach=approach,
        risk_level=opportunity.risk_level,
    )

    messages = [
        LLMMessage(role="system", content=system_prompt),
        LLMMessage(role="user", content=prompt),
    ]

    try:
        response = await provider.complete(messages, _patchgen_config(config))
    except LLMProviderError as exc:
        logger.error("Patch generation LLM call failed: %s", exc)
        return PatchGenTryRecord(
            attempt_number=attempt_number,
            success=False,
            failure_stage=PATCHGEN_FAILURE_STAGE_LLM_CALL,
            failure_reason=str(exc),
            patch=None,
            patch_trace=None,
        )

    patch, failure_stage, failure_reason = _parse_patch_response_detailed(
        response.content,
        response.thinking_trace,
        file_contents={file_rel_path: content},
    )
    return PatchGenTryRecord(
        attempt_number=attempt_number,
        success=patch is not None,
        failure_stage=failure_stage,
        failure_reason=failure_reason,
        patch=patch,
        patch_trace=patch.thinking_trace if patch else response.thinking_trace,
    )


def apply_search_replace(content: str, search: str, replace: str) -> str:
    """Apply a single search/replace edit to file content.

    Args:
        content: The full current file content.
        search: The exact text to find (must appear exactly once).
        replace: The text to substitute in its place.

    Returns:
        The modified file content.

    Raises:
        ValueError: If the search block is not found, or is found more than once
            (ambiguous), since applying to the wrong location would corrupt the file.
    """
    if not search:
        raise ValueError("search block is empty")

    count = content.count(search)
    if count == 0:
        preview = search[:120].replace("\n", "\\n")
        raise ValueError(
            f"search block not found in file (first 120 chars: {preview!r})"
        )
    if count > 1:
        preview = search[:120].replace("\n", "\\n")
        raise ValueError(
            f"search block appears {count} times — add more context to make it unique "
            f"(first 120 chars: {preview!r})"
        )

    return content.replace(search, replace, 1)


def edits_to_unified_diff(
    file_rel_path: str,
    original_content: str,
    edits: list[dict],
) -> str:
    """Apply search/replace edits and produce a unified diff via difflib.

    All edits for a file are applied sequentially to the running content.
    The diff is generated by Python — not by the LLM — so it is always
    syntactically correct.

    Args:
        file_rel_path: Repo-relative file path (used in diff headers).
        original_content: File content before any edits.
        edits: List of dicts with "search" and "replace" keys.

    Returns:
        A unified diff string (empty string if the edits produce no change).

    Raises:
        ValueError: Propagated from apply_search_replace on search failures.
    """
    current = original_content
    for edit in edits:
        current = apply_search_replace(
            current,
            search=edit["search"],
            replace=edit["replace"],
        )

    if current == original_content:
        return ""

    diff_lines = difflib.unified_diff(
        original_content.splitlines(keepends=True),
        current.splitlines(keepends=True),
        fromfile=f"a/{file_rel_path}",
        tofile=f"b/{file_rel_path}",
    )
    return "".join(diff_lines)


def _parse_patch_response(
    raw: str,
    thinking_trace: Optional[ThinkingTrace],
    file_contents: Optional[dict[str, str]] = None,
) -> Optional[AgentPatch]:
    """Parse the patch generation JSON response into an AgentPatch."""
    patch, _failure_stage, _failure_reason = _parse_patch_response_detailed(
        raw, thinking_trace, file_contents
    )
    return patch


def _parse_patch_response_detailed(
    raw: str,
    thinking_trace: Optional[ThinkingTrace],
    file_contents: Optional[dict[str, str]] = None,
) -> tuple[Optional[AgentPatch], Optional[str], Optional[str]]:
    """Parse the patch response and return (patch, failure_stage, failure_reason).

    Args:
        raw: Raw LLM response text.
        thinking_trace: Optional thinking trace from the LLM.
        file_contents: Mapping of repo-relative file path → original file content,
            required to apply the search/replace edits and generate the unified diff.
    """
    if not raw:
        return None, PATCHGEN_FAILURE_STAGE_NULL_DIFF, "empty response"
    cleaned = _strip_markdown_fences(raw)
    try:
        data = json.loads(cleaned)
    except json.JSONDecodeError as exc:
        logger.warning("Could not parse patch response JSON: %s (raw: %r)", exc, raw[:200])
        return None, PATCHGEN_FAILURE_STAGE_JSON_PARSE, str(exc)

    edits = data.get("edits")
    if not edits:
        logger.debug("LLM returned empty edits — no patch for this opportunity")
        return None, PATCHGEN_FAILURE_STAGE_NULL_DIFF, "LLM returned empty edits list"

    if not isinstance(edits, list):
        return None, PATCHGEN_FAILURE_STAGE_JSON_PARSE, "'edits' is not a list"

    title = str(data.get("title") or "")
    explanation = str(data.get("explanation") or "")
    estimated = int(data.get("estimated_lines_changed", 0) or 0)

    # Derive touched_files from the edits themselves
    touched_files = list({str(e.get("file", "")) for e in edits if e.get("file")})

    # Apply search/replace edits per file to produce a unified diff
    all_diff_chunks: list[str] = []
    contents = file_contents or {}

    for file_path in touched_files:
        file_edits = [e for e in edits if str(e.get("file", "")) == file_path]
        original_content = contents.get(file_path, "")
        try:
            diff_chunk = edits_to_unified_diff(file_path, original_content, file_edits)
        except ValueError as exc:
            reason = f"search/replace failed for {file_path}: {exc}"
            logger.warning("Patch search/replace failed: %s", reason)
            return None, PATCHGEN_FAILURE_STAGE_SEARCH_NOT_FOUND, reason

        if diff_chunk:
            all_diff_chunks.append(diff_chunk)

    combined_diff = "".join(all_diff_chunks)

    if not combined_diff.strip():
        return None, PATCHGEN_FAILURE_STAGE_NULL_DIFF, "edits produced no changes"

    return AgentPatch(
        diff=combined_diff,
        explanation=explanation,
        title=title,
        touched_files=touched_files,
        estimated_lines_changed=estimated,
        thinking_trace=thinking_trace,
    ), None, None


def _build_correction_feedback(
    previous_approach: str,
    failure_stage: str,
    failure_reason: str,
) -> str:
    """Return an augmented approach string that instructs the LLM to fix its mistake.

    Called when the first patch generation attempt fails in a recoverable way.
    The corrective message is appended to the original approach so the LLM has
    full context on both the task and what went wrong.
    """
    if failure_stage == PATCHGEN_FAILURE_STAGE_SEARCH_NOT_FOUND:
        return (
            f"{previous_approach}\n\n"
            f"PREVIOUS ATTEMPT FAILED — search block not found.\n"
            f"Error detail: {failure_reason}\n\n"
            "The search text you provided does not appear verbatim in the file.\n"
            "To fix this:\n"
            "1. Re-read the file content shown above very carefully.\n"
            "2. Copy the exact characters from the file — do NOT paraphrase, re-indent,\n"
            "   or change any whitespace, quotes, or punctuation.\n"
            "3. Include at least 5 lines of surrounding context so the block is unique.\n"
            "4. If you cannot find the exact text, respond with empty edits."
        )
    if failure_stage == PATCHGEN_FAILURE_STAGE_JSON_PARSE:
        return (
            f"{previous_approach}\n\n"
            "PREVIOUS ATTEMPT FAILED — response was not valid JSON.\n"
            f"Error detail: {failure_reason}\n\n"
            "Return ONLY the JSON object described in the instructions — "
            "no markdown fences, no extra prose, no trailing commas."
        )
    return previous_approach


def _parse_file_from_location(location: str) -> str:
    """Extract file path from a location string like 'src/utils.ts:42'."""
    if ":" not in location:
        return location
    return location.rsplit(":", 1)[0]


def _strip_markdown_fences(raw: str) -> str:
    """Strip a surrounding Markdown code fence (```json ... ```) if present."""
    text = raw.strip()
    if not text.startswith("```"):
        return text

    lines = text.splitlines()
    if not lines:
        return text
    if not lines[0].startswith("```"):
        return text

    if len(lines) >= 2 and lines[-1].strip() == "```":
        return "\n".join(lines[1:-1]).strip()

    return text
